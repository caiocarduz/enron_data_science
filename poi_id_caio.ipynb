{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caio\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 19 columns):\n",
      "poi                          146 non-null bool\n",
      "bonus                        82 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "other                        93 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "salary                       95 non-null float64\n",
      "dtypes: bool(1), float64(18)\n",
      "memory usage: 21.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 19 columns):\n",
      "poi                          146 non-null bool\n",
      "bonus                        146 non-null float64\n",
      "deferred_income              146 non-null float64\n",
      "deferral_payments            146 non-null float64\n",
      "loan_advances                146 non-null float64\n",
      "other                        146 non-null float64\n",
      "expenses                     146 non-null float64\n",
      "director_fees                146 non-null float64\n",
      "total_payments               146 non-null float64\n",
      "exercised_stock_options      146 non-null float64\n",
      "restricted_stock             146 non-null float64\n",
      "restricted_stock_deferred    146 non-null float64\n",
      "total_stock_value            146 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "salary                       95 non-null float64\n",
      "dtypes: bool(1), float64(18)\n",
      "memory usage: 21.8+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caio\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:113: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "poi                          146 non-null bool\n",
      "bonus                        146 non-null float64\n",
      "deferred_income              146 non-null float64\n",
      "deferral_payments            146 non-null float64\n",
      "loan_advances                146 non-null float64\n",
      "other                        146 non-null float64\n",
      "expenses                     146 non-null float64\n",
      "director_fees                146 non-null float64\n",
      "total_payments               146 non-null float64\n",
      "exercised_stock_options      146 non-null float64\n",
      "restricted_stock             146 non-null float64\n",
      "restricted_stock_deferred    146 non-null float64\n",
      "total_stock_value            146 non-null float64\n",
      "to_messages                  146 non-null float64\n",
      "from_messages                146 non-null float64\n",
      "from_this_person_to_poi      146 non-null float64\n",
      "from_poi_to_this_person      146 non-null float64\n",
      "long_term_incentive          146 non-null float64\n",
      "salary                       146 non-null float64\n",
      "poi_to_email                 146 non-null float64\n",
      "poi_from_email               146 non-null float64\n",
      "dtypes: bool(1), float64(20)\n",
      "memory usage: 24.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xca0b7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import numpy as np\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import neighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "#define as principais features antes da remoção de outliers e null values.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "feature_list_1 =['poi',\n",
    "                'bonus',\n",
    "                'deferred_income', \n",
    "                'deferral_payments',\n",
    "                'loan_advances', \n",
    "                'other',\n",
    "                'expenses', \n",
    "                'director_fees',\n",
    "                'total_payments',\n",
    "                'exercised_stock_options',\n",
    "                'restricted_stock',\n",
    "                'restricted_stock_deferred',\n",
    "                'total_stock_value',\n",
    "                'to_messages',\n",
    "                'from_messages',\n",
    "                'from_this_person_to_poi',\n",
    "                'from_poi_to_this_person', 'long_term_incentive', 'salary']\n",
    "\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict_1 = pickle.load(data_file)\n",
    "\n",
    "\n",
    "#CreateExercisedStockRatio(data_dict_1, feature_list_1)\n",
    "\n",
    "# funcao que classifica as features quanto sua importância############################\n",
    "def bestfeatures(data_dict_1, feature_list_1):\n",
    "    selector = SelectKBest(f_classif, k = len(feature_list_1)-1)\n",
    "    ### Store to my_dataset for easy export below.\n",
    "    my_dataset = data_dict_1\n",
    "### Extract features and labels from dataset for local testing\n",
    "    data_1 = featureFormat(my_dataset, feature_list_1, sort_keys = True)\n",
    "    labels_1, features_1 = targetFeatureSplit(data_1)\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    features_train_1, features_test_1, labels_train_1, labels_test_1 = train_test_split(features_1, labels_1, test_size=0.01, random_state=42)\n",
    "        \n",
    "    selector.fit(features_train_1, labels_train_1)\n",
    "    scores = -np.log10(selector.pvalues_)\n",
    "    return selector \n",
    "\n",
    "######################################################################################\n",
    "# descomentar para plot das Kbesst Selector###########################################\n",
    "#plt.bar(range(len(feature_list_1[1:])), bestfeatures(data_dict_1, feature_list_1))\n",
    "#plt.xticks(range(len(feature_list_1[1:])), feature_list_1[1:], rotation = 'vertical')\n",
    "#plt.show()\n",
    "#######################################################################################\n",
    "\n",
    "scores_1 = bestfeatures(data_dict_1, feature_list_1).scores_\n",
    "tuples = zip(feature_list_1[1:], scores_1)\n",
    "k_best_features = sorted(tuples, key = lambda x: x[1], reverse = True)\n",
    "kbest_inicial = k_best_features\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "# estratégia de manipular e editar os dados por meio do pandas obtida aqui:\n",
    "#https://olegleyz.github.io/enron_classifier.html\n",
    "df = pd.DataFrame.from_dict(data_dict_1, orient = 'index')\n",
    "df = df[feature_list_1]\n",
    "df = df.replace('NaN', np.nan)\n",
    "df.info()\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "# Substitui 'NaN' por 0\n",
    "# =============================================================================\n",
    "df.ix[:,:13] = df.ix[:,:13].fillna(0)\n",
    "df.ix[:,19:20] = df.ix[:,19:20].fillna(0)\n",
    "df.replace('inf',0)\n",
    "df.info()\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "df['to_messages'] = df['to_messages'].fillna((df['to_messages'].mean()))\n",
    "df['from_messages'] = df['from_messages'].fillna((df['from_messages'].mean()))\n",
    "df['from_this_person_to_poi'] = df['from_this_person_to_poi'].fillna((df['from_this_person_to_poi'].mean()))\n",
    "#df['long_term_incentive'] = df['long_term_incentive'].fillna((df['long_term_incentive'].mean()))\n",
    "df['long_term_incentive'] = df['long_term_incentive'].fillna(0)\n",
    "df['from_poi_to_this_person'] = df['from_poi_to_this_person'].fillna((df['from_poi_to_this_person'].mean()))\n",
    "#df['salary'] = df['salary'].fillna((df['salary'].median()))\n",
    "df['salary'] = df['salary'].fillna(0)\n",
    "df.replace('inf',0)\n",
    "\n",
    "\n",
    "##cria nova feature\n",
    "df['poi_to_email'] = df['from_this_person_to_poi']/df['to_messages']\n",
    "df['poi_from_email'] = df['from_poi_to_this_person']/df['from_messages']\n",
    "df.info()\n",
    "\n",
    "# =============================================================================\n",
    "# #Remove os null values e substitui pela média. utiliza Sklearn prepro\n",
    "# \n",
    "# features = ['to_messages', 'from_messages', 'from_this_person_to_poi', 'from_poi_to_this_person','salary', 'long_term_incentive',           'bonus']\n",
    "# \n",
    "# imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "# \n",
    "# #impute missing values of email features \n",
    "# df.loc[df[df.poi == 1].index,features] = imp.fit_transform(df[features][df.poi == 1])\n",
    "# df.loc[df[df.poi == 0].index,features] = imp.fit_transform(df[features][df.poi == 0])\n",
    "# \n",
    "# df.info()\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "# lista as features mais relevantes no metodo Kselector.\n",
    "feature_list_2 = ['poi',\n",
    "                'bonus',\n",
    "                'deferred_income', \n",
    "                'deferral_payments',\n",
    "                'loan_advances', \n",
    "                'other',\n",
    "                'expenses', \n",
    "                'director_fees',\n",
    "                'total_payments',\n",
    "                'exercised_stock_options',\n",
    "                'restricted_stock',\n",
    "                'restricted_stock_deferred',\n",
    "                'total_stock_value',\n",
    "                'to_messages',\n",
    "                'from_messages',\n",
    "                'from_this_person_to_poi',\n",
    "                'from_poi_to_this_person', 'long_term_incentive', 'salary', 'poi_to_email','poi_from_email']\n",
    "\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    " # You will need to use more features\n",
    "    \n",
    "my_dataset = df[feature_list_2].to_dict(orient = 'index')\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "\n",
    "my_dataset.pop(\"TOTAL\", 0)\n",
    "\n",
    "\n",
    "### define as melhores variaveis pelo metodo Kselector. \n",
    "\n",
    "#bestfeatures(my_dataset, feature_list_1)\n",
    "\n",
    "# Para plotar os Scores do Kbest Selector descomente abaixo ###########################\n",
    "#plt.bar(range(len(feature_list_1[1:])), bestfeatures(my_dataset, feature_list_1))\n",
    "#plt.xticks(range(len(feature_list_1[1:])), feature_list_1[1:], rotation = 'vertical')\n",
    "#plt.show()\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "scores_2 = bestfeatures(my_dataset, feature_list_2).scores_\n",
    "tuples = zip(feature_list_2[1:], scores_2)\n",
    "k_best_features = sorted(tuples, key = lambda x: x[1], reverse = True)\n",
    "kbest_tratado = k_best_features\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "# inspirado no código oferecido em https://www.kaggle.com/grfiv4/plotting-feature-importances\n",
    "\n",
    "#Decision tree using features with non-null importance\n",
    "clf = DecisionTreeClassifier(random_state = 75)\n",
    "clf.fit(df.ix[:,1:], df.ix[:,:1])\n",
    "dftrain = df.ix[:,1:]\n",
    "top_n = 20\n",
    "\n",
    "# show the features with non null importance, sorted and create features_list of features for the model\n",
    "feat_imp = pd.DataFrame({'importance':clf.feature_importances_})    \n",
    "feat_imp['feature'] = dftrain.columns\n",
    "feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feat_imp = feat_imp.iloc[:top_n]\n",
    "    \n",
    "feat_imp.sort_values(by='importance', inplace=True)\n",
    "feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "feat_imp.plot.barh(title=\"features importance\", figsize=(8,8))\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "\n",
    "## descomentar caso for utilizar o metodo pipeline.#####################################\n",
    "\n",
    "features_list = feature_list_2\n",
    "\n",
    "########################################################################################\n",
    "#features_list = ['poi',\n",
    "#                'other',\n",
    "#                'expenses', \n",
    "#                'total_payments',\n",
    "#                'from_messages',\n",
    "#                'from_this_person_to_poi',\n",
    "#                'from_poi_to_this_person', 'long_term_incentive', 'poi_to_email','bonus',\n",
    "#                'restricted_stock', 'exercised_stock_options','salary']\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "\n",
    "##### Provided to give you a starting point. Try a variety of classifiers.#############\n",
    "\n",
    "#clff = DecisionTreeClassifier(class_weight = {1:10,0:6},min_samples_split = 45,random_state = 29,max_depth = None)\n",
    "\n",
    "#### descomentar caso for utilizar o metodo pipeline. Descomentar somente um classificador por vez.#####\n",
    "#clff = GaussianNB()\n",
    "#clff = RandomForestClassifier(min_samples_split = 10)\n",
    "#clff = neighbors.kNeighborsClassifier(n_neighbors = 6)\n",
    "#clff = linear_model.LogisticRegression( C=1e5)\n",
    "clff = KMeans(n_clusters =2)\n",
    "#clff = SVC()\n",
    "########################################################################################################\n",
    "\n",
    "####### Para pipeline descomentar as variaveis abaixo #######################################\n",
    "#pca1 = PCA(n_components = 2)\n",
    "selector = SelectKBest(f_classif, k = 5)\n",
    "scaler = MinMaxScaler()\n",
    "clf = Pipeline([(\"selector\",selector),('scaler', scaler), ('clf', clff)])\n",
    "##############################################################################################\n",
    "\n",
    "### Pra GridSearch descomentar estimator, parameters e clf ###################################\n",
    "#estimators = [('reduce_dim', PCA()), ('clf', DecisionTreeClassifier())]\n",
    "\n",
    "#parameters = {'reduce_dim__n_components': [1, 2], 'clf__min_samples_split': [2, 4, 6, 8]}\n",
    "\n",
    "#clf = GridSearchCV(Pipeline(estimators), parameters, scoring =\"average_precision\")\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test =     train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "####  GridSearchCV metricas ###################################################\n",
    "\n",
    "#clf.fit(features_train, labels_train)\n",
    "#print clf.cv_results_\n",
    "#print clf.best_estimator_\n",
    "#print clf.best_score_\n",
    "#print clf.best_params_\n",
    "#y_pred = clf.predict(features_test)\n",
    "#print (len(features_test))\n",
    "#print (accuracy_score(labels_test, y_pred))\n",
    "#print (recall_score(labels_test, y_pred))\n",
    "#print (confusion_matrix(labels_test, y_pred))\n",
    "#print(metrics.classification_report(labels_test, y_pred)) \n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
