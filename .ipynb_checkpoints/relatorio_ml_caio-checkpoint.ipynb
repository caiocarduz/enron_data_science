{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuração inicial, somente a feature Salary.\n",
    "\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.25560\tPrecision: 0.18481\tRecall: 0.79800\tF1: 0.30011\tF2: 0.47968\n",
    "\tTotal predictions: 10000\tTrue positives: 1596\tFalse positives: 7040\tFalse negatives:  404\tTrue negatives:  960\n",
    "\n",
    "\n",
    "Config inicial porem com rescolanamento de todas as features\n",
    "    GaussianNB(priors=None)\n",
    "\tAccuracy: 0.33800\tPrecision: 0.15456\tRecall: 0.88700\tF1: 0.26324\tF2: 0.45539\n",
    "\tTotal predictions: 15000\tTrue positives: 1774\tFalse positives: 9704\tFalse negatives:  226\tTrue negatives: 3296\n",
    "\n",
    "Config com 2 features shared poi e loan advance \n",
    "    GaussianNB(priors=None)\n",
    "\tAccuracy: 0.33585\tPrecision: 0.16857\tRecall: 0.84350\tF1: 0.28098\tF2: 0.46840\n",
    "\tTotal predictions: 13000\tTrue positives: 1687\tFalse positives: 8321\tFalse negatives:  313\tTrue negatives: 2679\n",
    "\n",
    "\n",
    "Randon forest com 10 estimadores\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\tAccuracy: 0.84940\tPrecision: 0.30408\tRecall: 0.10050\tF1: 0.15107\tF2: 0.11604\n",
    "\tTotal predictions: 15000\tTrue positives:  201\tFalse positives:  460\tFalse negatives: 1799\tTrue negatives: 12540\n",
    "    \n",
    "    Notar maior acuracia, no entanto menor precisão e recall levando F1 ser a metade do naive bayes. \n",
    "    Provavelmente o grande numero de features tenha sido o grande vilão. Re-escalar os dados pode ser uma alternativa, ou usar um numero menor de estimadores.\n",
    "    \n",
    "Rabdom forest com um estimador shared poi\n",
    "    andomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\tAccuracy: 0.83767\tPrecision: 0.26741\tRecall: 0.26500\tF1: 0.26620\tF2: 0.26548\n",
    "\tTotal predictions: 9000\tTrue positives:  265\tFalse positives:  726\tFalse negatives:  735\tTrue negatives: 7274\n",
    "    \n",
    "random forest shared poi and loan advance\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\tAccuracy: 0.85011\tPrecision: 0.28848\tRecall: 0.23800\tF1: 0.26082\tF2: 0.24663\n",
    "\tTotal predictions: 9000\tTrue positives:  238\tFalse positives:  587\tFalse negatives:  762\tTrue negatives: 7413\n",
    "\n",
    "random forest shared poi and loan advance e total payments. muito pior.\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\tAccuracy: 0.81386\tPrecision: 0.16776\tRecall: 0.07650\tF1: 0.10508\tF2: 0.08584\n",
    "\tTotal predictions: 14000\tTrue positives:  153\tFalse positives:  759\tFalse negatives: 1847\tTrue negatives: 11241\n",
    "\n",
    "Random com loan advance e salary muito pior que aqueles com features mais significativas.\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\tAccuracy: 0.70870\tPrecision: 0.19987\tRecall: 0.15200\tF1: 0.17268\tF2: 0.15965\n",
    "\tTotal predictions: 10000\tTrue positives:  304\tFalse positives: 1217\tFalse negatives: 1696\tTrue negatives: 6783\n",
    "\n",
    "Randon forest com 3 estimadores.\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=3, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\tAccuracy: 0.82720\tPrecision: 0.29919\tRecall: 0.22050\tF1: 0.25389\tF2: 0.23274\n",
    "\tTotal predictions: 15000\tTrue positives:  441\tFalse positives: 1033\tFalse negatives: 1559\tTrue negatives: 11967\n",
    "\n",
    "    Resultado melhor que com 10 porém pior que o naive bayes.\n",
    "    \n",
    "decision tree com todas as features \n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "\tAccuracy: 0.80920\tPrecision: 0.27505\tRecall: 0.26350\tF1: 0.26915\tF2: 0.26573\n",
    "\tTotal predictions: 15000\tTrue positives:  527\tFalse positives: 1389\tFalse negatives: 1473\tTrue negatives: 11611\n",
    "\n",
    " \n",
    "Decision tree com  shared poi and loan advance. acima de 0.3 !!!!!\n",
    " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "\tAccuracy: 0.85611\tPrecision: 0.34054\tRecall: 0.31500\tF1: 0.32727\tF2: 0.31980\n",
    "\tTotal predictions: 9000\tTrue positives:  315\tFalse positives:  610\tFalse negatives:  685\tTrue negatives: 7390\n",
    "\n",
    "decision tree com apenas shared poi\n",
    "\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "\tAccuracy: 0.84211\tPrecision: 0.30198\tRecall: 0.32100\tF1: 0.31120\tF2: 0.31701\n",
    "\tTotal predictions: 9000\tTrue positives:  321\tFalse positives:  742\tFalse negatives:  679\tTrue negatives: 7258\n",
    "  \n",
    "SVC, apraentemente classificadores lineares não são bons para reconher distribuições assimetricas. resultado muito ruim.\n",
    "Pipeline(memory=None,\n",
    "     steps=[('SelectKbest', SelectKBest(k=2, score_func=<function f_classif at 0x0000000009990588>)), ('rescalar', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False))])\n",
    "\tAccuracy: 0.86313\tPrecision: 0.13699\tRecall: 0.00500\tF1: 0.00965\tF2: 0.00619\n",
    "\tTotal predictions: 15000\tTrue positives:   10\tFalse positives:   63\tFalse negatives: 1990\tTrue negatives: 12937\n",
    "\n",
    "  \n",
    "  \n",
    "Utilizando pipeline com PCA(5 componentes) e dcision tree pior que com 2 features.\n",
    "Pipeline(memory=None,\n",
    "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))])\n",
    "\tAccuracy: 0.80967\tPrecision: 0.26368\tRecall: 0.23850\tF1: 0.25046\tF2: 0.24314\n",
    "\tTotal predictions: 15000\tTrue positives:  477\tFalse positives: 1332\tFalse negatives: 1523\tTrue negatives: 11668\n",
    "\n",
    "Utilizando pipeline para decidir as melhores features gera disparidade em relação a escolha manual e reduz precision e recall\n",
    "Pipeline(memory=None,\n",
    "     steps=[('SelectKbest', SelectKBest(k=2, score_func=<function f_classif at 0x0000000009990588>)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))])\n",
    "\tAccuracy: 0.82933\tPrecision: 0.28528\tRecall: 0.18600\tF1: 0.22518\tF2: 0.19991\n",
    "\tTotal predictions: 15000\tTrue positives:  372\tFalse positives:  932\tFalse negatives: 1628\tTrue negatives: 12068\n",
    "\n",
    "\n",
    "usando pca para apenas duas features shared poi e loan advance. melhor até aqui !!!!!!\n",
    "\n",
    "Pipeline(memory=None,\n",
    "     steps=[('PCA', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))])\n",
    "\tAccuracy: 0.85822\tPrecision: 0.34902\tRecall: 0.31900\tF1: 0.33333\tF2: 0.32458\n",
    "\tTotal predictions: 9000\tTrue positives:  319\tFalse positives:  595\tFalse negatives:  681\tTrue negatives: 7405\n",
    "    \n",
    "    2 features porem 2 componentes de pca\n",
    "    Pipeline(memory=None,\n",
    "     steps=[('PCA', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))])\n",
    "\tAccuracy: 0.85833\tPrecision: 0.35038\tRecall: 0.32200\tF1: 0.33559\tF2: 0.32730\n",
    "\tTotal predictions: 9000\tTrue positives:  322\tFalse positives:  597\tFalse negatives:  678\tTrue negatives: 7403\n",
    "\n",
    "\n",
    "usando para as tres mehlores features aumentou bastante a precisão porém reduziu o recall, aumentou numero de falsos positivos\n",
    "peline(memory=None,\n",
    "     steps=[('PCA', PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))])\n",
    "\tAccuracy: 0.80082\tPrecision: 0.43144\tRecall: 0.30050\tF1: 0.35426\tF2: 0.31992\n",
    "\tTotal predictions: 11000\tTrue positives:  601\tFalse positives:  792\tFalse negatives: 1399\tTrue negatives: 8208\n",
    "    \n",
    " rescalado, duas features alem de shared recepit loan advances\n",
    " \n",
    " Pipeline(memory=None,\n",
    "     steps=[('rescalar', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))])\n",
    "\tAccuracy: 0.82692\tPrecision: 0.40876\tRecall: 0.28000\tF1: 0.33234\tF2: 0.29883\n",
    "\tTotal predictions: 13000\tTrue positives:  560\tFalse positives:  810\tFalse negatives: 1440\tTrue negatives: 10190\n",
    "\n",
    "\n",
    "pca duas features alem de de shared recepit e lon advances\n",
    "\n",
    "Pipeline(memory=None,\n",
    "     steps=[('PCA', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))])\n",
    "\tAccuracy: 0.83938\tPrecision: 0.45985\tRecall: 0.25200\tF1: 0.32558\tF2: 0.27704\n",
    "\tTotal predictions: 13000\tTrue positives:  504\tFalse positives:  592\tFalse negatives: 1496\tTrue negatives: 10408\n",
    "    \n",
    "    \n",
    "    Estrategia com grid search\n",
    "    \n",
    "    2 criadas e loan e poi shared\n",
    "    GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=Pipeline(memory=None,\n",
    "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impu...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))]),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid={'reduce_dim__n_components': [1, 2, 3], 'clf__min_samples_split': [2, 4, 6, 8]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring='f1', verbose=0)\n",
    "\tAccuracy: 0.82808\tPrecision: 0.39897\tRecall: 0.23200\tF1: 0.29339\tF2: 0.25319\n",
    "\tTotal predictions: 13000\tTrue positives:  464\tFalse positives:  699\tFalse negatives: 1536\tTrue negatives: 10301\n",
    "{'reduce_dim__n_components': 3, 'clf__min_samples_split': 2}\n",
    "\n",
    "\n",
    "duas loan e shared poi scoring = F1\n",
    "GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=Pipeline(memory=None,\n",
    "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impu...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'))]),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid={'reduce_dim__n_components': [1, 2], 'clf__min_samples_split': [2, 4, 6, 8]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring='f1', verbose=0)\n",
    "\tAccuracy: 0.84978\tPrecision: 0.29770\tRecall: 0.25900\tF1: 0.27701\tF2: 0.26591\n",
    "\tTotal predictions: 9000\tTrue positives:  259\tFalse positives:  611\tFalse negatives:  741\tTrue negatives: 7389\n",
    "\n",
    "{'reduce_dim__n_components': 2, 'clf__min_samples_split': 2}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
