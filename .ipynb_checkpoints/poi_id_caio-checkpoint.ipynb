{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import numpy as np\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import neighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A forma de se criar novas features foram obtidas no seguinte endereco\n",
    "#https://github.com/nehal96/Machine-Learning-Enron-Fraud/blob/master/final_project/poi_id.py\n",
    "###############################################################################################\n",
    "def CreatePoiEmailRatio(data_dict, features_list):\n",
    "    \"\"\"\n",
    "    Adds a new feature to the feature list: POI Email Ratio.\n",
    "    \"\"\"\n",
    "    features = ['from_messages', 'to_messages', 'from_poi_to_this_person',\n",
    "                'from_this_person_to_poi']\n",
    "    for key in data_dict:\n",
    "        employee = data_dict[key]\n",
    "        is_valid = True\n",
    "        for feature in features:\n",
    "            if employee[feature] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            total_from = employee['from_poi_to_this_person'] + employee['from_messages']\n",
    "            total_to = employee['from_this_person_to_poi'] + employee['to_messages']\n",
    "            to_poi_ratio = float(employee['from_this_person_to_poi']) / total_to\n",
    "            from_poi_ratio = float(employee['from_poi_to_this_person']) / total_from\n",
    "            employee['poi_email_ratio'] = to_poi_ratio + from_poi_ratio\n",
    "        else:\n",
    "            employee['poi_email_ratio'] = 'NaN'\n",
    "    features_list.append('poi_email_ratio')\n",
    "##############################################################################################\n",
    "\n",
    "def CreateExercisedStockRatio(data_dict, features_list):\n",
    "    \"\"\"\n",
    "    Adds a new feature to the feature list: Exercised Stock Ratio\n",
    "\n",
    "    \"\"\"\n",
    "    features = ['exercised_stock_options', 'total_stock_value']\n",
    "    for key in data_dict:\n",
    "        employee = data_dict[key]\n",
    "        is_valid = True\n",
    "        for feature in features:\n",
    "            if employee[feature] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            employee['exercised_stock_ratio'] = float(employee['exercised_stock_options']) / employee['total_stock_value']\n",
    "        else:\n",
    "            employee['exercised_stock_ratio'] = 'NaN'\n",
    "\n",
    "    features_list.append('exercised_stock_ratio')\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('poi_email_ratio', 16.892629030882777),\n",
       " ('from_poi_to_this_person', 5.291407922985095),\n",
       " ('loan_advances', 2.464310184687415),\n",
       " ('from_this_person_to_poi', 2.388275483350518),\n",
       " ('to_messages', 1.6623231397925644),\n",
       " ('director_fees', 0.5178811165508316),\n",
       " ('total_payments', 0.3363840421381841),\n",
       " ('deferral_payments', 0.24614293764627695),\n",
       " ('exercised_stock_options', 0.2184767555050677),\n",
       " ('deferred_income', 0.20787351033133175),\n",
       " ('from_messages', 0.16935276789195203),\n",
       " ('total_stock_value', 0.16000594105562424),\n",
       " ('bonus', 0.07137967248649994),\n",
       " ('other', 0.06908422547864544),\n",
       " ('restricted_stock', 0.031102163637404995),\n",
       " ('long_term_incentive', 0.019677037030621142),\n",
       " ('expenses', 0.015801580708091782),\n",
       " ('restricted_stock_deferred', 0.004239149928831463),\n",
       " ('salary', 0.00047652844982604)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define as principais features antes da remoção de outliers e null values.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "feature_list_1 =['poi',\n",
    "                'bonus',\n",
    "                'deferred_income', \n",
    "                'deferral_payments',\n",
    "                'loan_advances', \n",
    "                'other',\n",
    "                'expenses', \n",
    "                'director_fees',\n",
    "                'total_payments',\n",
    "                'exercised_stock_options',\n",
    "                'restricted_stock',\n",
    "                'restricted_stock_deferred',\n",
    "                'total_stock_value',\n",
    "                'to_messages',\n",
    "                'from_messages',\n",
    "                'from_this_person_to_poi',\n",
    "                'from_poi_to_this_person', 'long_term_incentive', 'salary']\n",
    "\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict_1 = pickle.load(data_file)\n",
    "CreatePoiEmailRatio(data_dict_1, feature_list_1)\n",
    "\n",
    "#CreateExercisedStockRatio(data_dict_1, feature_list_1)\n",
    "\n",
    "# funcao que classifica as features quanto sua importância############################\n",
    "def bestfeatures(data_dict_1, feature_list_1):\n",
    "    selector = SelectKBest(f_classif, k = len(feature_list_1)-1)\n",
    "    ### Store to my_dataset for easy export below.\n",
    "    my_dataset = data_dict_1\n",
    "### Extract features and labels from dataset for local testing\n",
    "    data_1 = featureFormat(my_dataset, feature_list_1, sort_keys = True)\n",
    "    labels_1, features_1 = targetFeatureSplit(data_1)\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    features_train_1, features_test_1, labels_train_1, labels_test_1 = \\\n",
    "        train_test_split(features_1, labels_1, test_size=0.01, random_state=42)\n",
    "        \n",
    "    selector.fit(features_train_1, labels_train_1)\n",
    "    scores = -np.log10(selector.pvalues_)\n",
    "    return selector \n",
    "\n",
    "######################################################################################\n",
    "# descomentar para plot das Kbesst Selector###########################################\n",
    "#plt.bar(range(len(feature_list_1[1:])), bestfeatures(data_dict_1, feature_list_1))\n",
    "#plt.xticks(range(len(feature_list_1[1:])), feature_list_1[1:], rotation = 'vertical')\n",
    "#plt.show()\n",
    "#######################################################################################\n",
    "\n",
    "scores_1 = bestfeatures(data_dict_1, feature_list_1).scores_\n",
    "tuples = zip(feature_list_1[1:], scores_1)\n",
    "k_best_features = sorted(tuples, key = lambda x: x[1], reverse = True)\n",
    "k_best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null bool\n",
      "bonus                        82 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "other                        93 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "salary                       95 non-null float64\n",
      "poi_email_ratio              86 non-null float64\n",
      "dtypes: bool(1), float64(19)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# estratégia de manipular e editar os dados por meio do pandas obtida aqui:\n",
    "#https://olegleyz.github.io/enron_classifier.html\n",
    "df = pd.DataFrame.from_dict(data_dict_1, orient = 'index')\n",
    "df = df[feature_list_1]\n",
    "df = df.replace('NaN', np.nan)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null bool\n",
      "bonus                        146 non-null float64\n",
      "deferred_income              146 non-null float64\n",
      "deferral_payments            146 non-null float64\n",
      "loan_advances                146 non-null float64\n",
      "other                        146 non-null float64\n",
      "expenses                     146 non-null float64\n",
      "director_fees                146 non-null float64\n",
      "total_payments               146 non-null float64\n",
      "exercised_stock_options      146 non-null float64\n",
      "restricted_stock             146 non-null float64\n",
      "restricted_stock_deferred    146 non-null float64\n",
      "total_stock_value            146 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "salary                       95 non-null float64\n",
      "poi_email_ratio              146 non-null float64\n",
      "dtypes: bool(1), float64(19)\n",
      "memory usage: 23.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caio\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Substitui 'NaN' por 0\n",
    "df.ix[:,:13] = df.ix[:,:13].fillna(0)\n",
    "df.ix[:,19:20] = df.ix[:,19:20].fillna(0)\n",
    "df.replace('inf',0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null bool\n",
      "bonus                        146 non-null float64\n",
      "deferred_income              146 non-null float64\n",
      "deferral_payments            146 non-null float64\n",
      "loan_advances                146 non-null float64\n",
      "other                        146 non-null float64\n",
      "expenses                     146 non-null float64\n",
      "director_fees                146 non-null float64\n",
      "total_payments               146 non-null float64\n",
      "exercised_stock_options      146 non-null float64\n",
      "restricted_stock             146 non-null float64\n",
      "restricted_stock_deferred    146 non-null float64\n",
      "total_stock_value            146 non-null float64\n",
      "to_messages                  146 non-null float64\n",
      "from_messages                146 non-null float64\n",
      "from_this_person_to_poi      146 non-null float64\n",
      "from_poi_to_this_person      146 non-null float64\n",
      "long_term_incentive          146 non-null float64\n",
      "salary                       146 non-null float64\n",
      "poi_email_ratio              146 non-null float64\n",
      "dtypes: bool(1), float64(19)\n",
      "memory usage: 28.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Remove os null values e substitui pela média. utiliza Sklearn prepro\n",
    "\n",
    "features = ['to_messages', 'from_messages', 'from_this_person_to_poi', 'from_poi_to_this_person','salary', 'long_term_incentive',\\\n",
    "           'bonus']\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "\n",
    "#impute missing values of email features \n",
    "df.loc[df[df.poi == 1].index,features] = imp.fit_transform(df[features][df.poi == 1])\n",
    "df.loc[df[df.poi == 0].index,features] = imp.fit_transform(df[features][df.poi == 0])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('poi_email_ratio', 16.892629030882777),\n",
       " ('from_poi_to_this_person', 5.291407922985095),\n",
       " ('loan_advances', 2.464310184687415),\n",
       " ('from_this_person_to_poi', 2.388275483350518),\n",
       " ('to_messages', 1.6623231397925644),\n",
       " ('director_fees', 0.5178811165508316),\n",
       " ('total_payments', 0.3363840421381841),\n",
       " ('deferral_payments', 0.24614293764627695),\n",
       " ('exercised_stock_options', 0.2184767555050677),\n",
       " ('deferred_income', 0.20787351033133175),\n",
       " ('from_messages', 0.16935276789195203),\n",
       " ('total_stock_value', 0.16000594105562424),\n",
       " ('bonus', 0.07137967248649994),\n",
       " ('other', 0.06908422547864544),\n",
       " ('restricted_stock', 0.031102163637404995),\n",
       " ('long_term_incentive', 0.019677037030621142),\n",
       " ('expenses', 0.015801580708091782),\n",
       " ('restricted_stock_deferred', 0.004239149928831463),\n",
       " ('salary', 0.00047652844982604)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    " # You will need to use more features\n",
    "    \n",
    "my_dataset = df[feature_list_1].to_dict(orient = 'index')\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "\n",
    "my_dataset.pop(\"TOTAL\", 0)\n",
    "\n",
    "\n",
    "### define as melhores variaveis pelo metodo Kselector. \n",
    "\n",
    "#bestfeatures(my_dataset, feature_list_1)\n",
    "\n",
    "# Para plotar os Scores do Kbest Selector descomente abaixo ###########################\n",
    "#plt.bar(range(len(feature_list_1[1:])), bestfeatures(my_dataset, feature_list_1))\n",
    "#plt.xticks(range(len(feature_list_1[1:])), feature_list_1[1:], rotation = 'vertical')\n",
    "#plt.show()\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# lista as features mais relevantes no metodo Kselector.\n",
    "\n",
    "\n",
    "scores_2 = bestfeatures(my_dataset, feature_list_1).scores_\n",
    "tuples = zip(feature_list_1[1:], scores_1)\n",
    "k_best_features = sorted(tuples, key = lambda x: x[1], reverse = True)\n",
    "k_best_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long_term_incentive', 0.4388049686926485]\n",
      "['from_this_person_to_poi', 0.19288225895732689]\n",
      "['other', 0.08449074074074071]\n",
      "['poi_email_ratio', 0.059407552083333315]\n",
      "['from_poi_to_this_person', 0.05912946795187656]\n",
      "['expenses', 0.05808738425925925]\n",
      "['total_payments', 0.05544704861111109]\n",
      "['from_messages', 0.051750578703703656]\n"
     ]
    }
   ],
   "source": [
    "# extraido  de https://olegleyz.github.io/enron_classifier.html\n",
    "\n",
    "#Decision tree using features with non-null importance\n",
    "clf = DecisionTreeClassifier(random_state = 75)\n",
    "clf.fit(df.ix[:,1:], df.ix[:,:1])\n",
    "\n",
    "# show the features with non null importance, sorted and create features_list of features for the model\n",
    "features_importance = []\n",
    "for i in range(len(clf.feature_importances_)):\n",
    "    if clf.feature_importances_[i] > 0:\n",
    "        features_importance.append([df.columns[i+1], clf.feature_importances_[i]])\n",
    "features_importance.sort(key=lambda x: x[1], reverse = True)\n",
    "for f_i in features_importance:\n",
    "    print f_i\n",
    "features_list = [x[0] for x in features_importance]\n",
    "features_list.insert(0, 'poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## descomentar caso for utilizar o metodo pipeline.#####################################\n",
    "\n",
    "#features_list = feature_list_1\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "\n",
    "##### Provided to give you a starting point. Try a variety of classifiers.#############\n",
    "\n",
    "clf = DecisionTreeClassifier(class_weight = {0:1.2},min_samples_split = 50,random_state = 295,max_depth = None)\n",
    "\n",
    "#### descomentar caso for utilizar o metodo pipeline. Descomentar somente um classificador por vez.#####\n",
    "#clff = GaussianNB()\n",
    "#clff = RandomForestClassifier(min_samples_split = 10)\n",
    "#clff = neighbors.kNeighborsClassifier(n_neighbors = 6)\n",
    "#clff = linear_model.LogisticRegression( C=1e5)\n",
    "#clf = KMeans(n_clusters =2)\n",
    "#clff = SVC()\n",
    "########################################################################################################\n",
    "\n",
    "####### Para pipeline descomentar as variaveis abaixo #######################################\n",
    "#pca1 = PCA(n_components = 7)\n",
    "#selector = SelectKBest(f_classif, k = 15)\n",
    "#scaler = MinMaxScaler()\n",
    "#clf = Pipeline([(\"rescalar\",scaler), (\"seletor\", selector), ('clf', clff)])\n",
    "##############################################################################################\n",
    "\n",
    "### Pra GridSearch descomentar estimator, parameters e clf ###################################\n",
    "#estimators = [('reduce_dim', PCA()), ('clf', DecisionTreeClassifier())]\n",
    "\n",
    "#parameters = {'reduce_dim__n_components': [1, 2], 'clf__min_samples_split': [2, 4, 6, 8]}\n",
    "\n",
    "#clf = GridSearchCV(Pipeline(estimators), parameters, scoring =\"average_precision\")\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "####  GridSearchCV metricas ###################################################\n",
    "\n",
    "#clf.fit(features_train, labels_train)\n",
    "#print clf.cv_results_\n",
    "#print clf.best_estimator_\n",
    "#print clf.best_score_\n",
    "#print clf.best_params_\n",
    "#y_pred = clf.predict(features_test)\n",
    "#print (len(features_test))\n",
    "#print (accuracy_score(labels_test, y_pred))\n",
    "#print (recall_score(labels_test, y_pred))\n",
    "#print (confusion_matrix(labels_test, y_pred))\n",
    "#print(metrics.classification_report(labels_test, y_pred)) \n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
